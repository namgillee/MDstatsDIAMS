#' Compute local false discovery rates from p-values
#'
#' The p-values are transformed to z-values, then, lfdr values are computed.
#' @param pvalues A vector of p-values
#' @return A vector of local fdr values, of the same length as pvalues
#' @export
local_fdr <- function(
  pvalues, known_target_df, eps = 5e-16
) {
  # Transform p-values to z-values
  # Because p-value is not symmetric (small p implies significance) but
  # z-value is symmetric (large z > 0 or small z < 0 implies significance),
  # z-values are generated by combining z and -z.
  one_minus_p <- 1 - pvalues[!is.na(pvalues)]
  one_minus_p[one_minus_p > (1 - eps)] <- 1 - eps
  z_pos <- qnorm(0.5 + one_minus_p / 2)
  zvalues <- c(z_pos, -z_pos)

  # Compute lfdr using z-values
  lfdr_out <- fdrtool::fdrtool(zvalues, "normal", plot = FALSE)

  # The output lfdr has the same length as p-values
  lfdr <- rep(NaN, length(pvalues))
  lfdr[!is.na(pvalues)] <- lfdr_out$lfdr[1 : sum(!is.na(pvalues))]

  return(lfdr)
}


#' Compute sensitivity and specificity from statistical significance result
#'
#' @param is_target A boolean vector for labeling true target.
#' @param q_values Significance levels. Smaller value implies more significance.
#' @param random_seed Random seed. Used for shuffling input values.
#' @return data frame of nine metrics: total, total_pos, total_neg, count_p,
#'   count_tp, count_fp, count_fn, specificity, sensitivity. The count_p
#'   increases from 1 to total across rows.
#' @export
compute_sensitivity_specificity_table <- function(
  is_target, q_values, random_seed = 11111
) {
  idx_not_na <- !is.na(is_target) & !is.na(q_values)
  is_target <- is_target[idx_not_na]
  q_values <- q_values[idx_not_na]

  if (length(is_target) != length(q_values)) {
    warning("Length of is_target must be equal to that of q_values.")
    return(NULL)
  }

  count_p <- count_tp <- count_fp <- count_fn <- specificity <- sensitivity <-
    double(length = length(q_values))

  ## constants
  total <- length(q_values)
  count_p <- 1 : total
  total_neg <- sum(!is_target)
  total_pos <- sum(is_target)
  
  ## variables
  ## Shuffling in this code block can be necessary when q-values has many
  ## duplicates. Once shuffled, re-ordering in the next line does not change
  ## the order within duplicated values.
  set.seed(random_seed)
  count_tp <- rep(0, total)
  for (rep in 1:100) {
    shuffhled_df <- dplyr::sample_frac(data.frame(is_target, q_values), 1L)
    shuffhled_df <- shuffhled_df[order(shuffhled_df$q_values), ]
    count_tp <- count_tp + cumsum(shuffhled_df$is_target) / 100
  }
  count_fp <- count_p - count_tp
  count_fn <- total_pos - count_tp
  specificity <- (total_neg - count_fp) / total_neg
  sensitivity <- count_tp / total_pos

  return(
    data.frame(
      total, total_pos, total_neg, count_p, count_tp, count_fp, count_fn,
      specificity, sensitivity
    )
  )
}
